# Whisper éˆæ´»é‹ç®—æœå‹™ä½¿ç”¨æŒ‡å—

## ğŸš€ åŠŸèƒ½ç‰¹è‰²

- **æœ¬åœ°é‹ç®—**: ä½¿ç”¨æœ¬æ©Ÿ CPU/GPU é‹è¡Œ Whisper æ¨¡å‹
- **é ç«¯é‹ç®—**: é€£æ¥åˆ°ä½ çš„å°ˆç”¨é‹ç®—ä¼ºæœå™¨
- **è‡ªå‹•åˆ‡æ›**: æ™ºèƒ½é¸æ“‡æœ€ä½³å¯ç”¨çš„é‹ç®—è³‡æº
- **åƒæ•¸åŒ–é…ç½®**: å¯é€é API å‹•æ…‹èª¿æ•´è¨­å®š
- **å¤šèªè¨€æ”¯æ´**: ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ“æ–‡ç­‰

## ğŸ“‹ éƒ¨ç½²æ–¹å¼

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨éˆæ´»ç‰ˆæœ¬ï¼ˆæ¨è–¦ï¼‰

```bash
# 1. é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd /volume3/ai-stack/meeting-minutes-automation/whisper-service

# 2. åœæ­¢ç¾æœ‰æœå‹™
docker-compose down

# 3. ä½¿ç”¨éˆæ´»ç‰ˆæœ¬
cp server-flexible.py server.py
cp docker-compose.flexible.yaml docker-compose.yaml

# 4. è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆå¯é¸ï¼‰
export COMPUTE_MODE=local          # é è¨­ä½¿ç”¨æœ¬åœ°é‹ç®—
export WHISPER_MODEL=base          # ä½¿ç”¨ base æ¨¡å‹
export WHISPER_LANG=zh             # é è¨­ä¸­æ–‡

# 5. å»ºç½®ä¸¦å•Ÿå‹•
docker-compose build --no-cache
docker-compose up -d

# 6. æª¢æŸ¥æœå‹™ç‹€æ…‹
curl http://localhost:10300/health
```

## ğŸ”§ é‹ç®—æ¨¡å¼è¨­å®š

### 1. æœ¬åœ°é‹ç®—æ¨¡å¼

```bash
# è¨­å®šç’°å¢ƒè®Šæ•¸
export COMPUTE_MODE=local
export WHISPER_MODEL=base  # å¯é¸: tiny, base, small, medium, large

# é‡å•Ÿæœå‹™
docker-compose down && docker-compose up -d
```

### 2. é ç«¯é‹ç®—æ¨¡å¼

```bash
# è¨­å®šé ç«¯ä¼ºæœå™¨
export COMPUTE_MODE=remote
export REMOTE_WHISPER_HOST=http://your-gpu-server:10300

# é‡å•Ÿæœå‹™
docker-compose down && docker-compose up -d
```

### 3. è‡ªå‹•é¸æ“‡æ¨¡å¼

```bash
# è‡ªå‹•é¸æ“‡æœ€ä½³é‹ç®—æ–¹å¼
export COMPUTE_MODE=auto
export REMOTE_WHISPER_HOST=http://your-gpu-server:10300  # å‚™ç”¨é¸é …

# é‡å•Ÿæœå‹™
docker-compose down && docker-compose up -d
```

## ğŸ“¡ API ä½¿ç”¨æ–¹å¼

### 1. å¥åº·æª¢æŸ¥

```bash
curl http://localhost:10300/health
```

å›æ‡‰ç¯„ä¾‹ï¼š
```json
{
  "status": "ok",
  "version": "2.0.0",
  "local_whisper_available": true,
  "remote_whisper_available": false,
  "available_modes": ["local"],
  "current_compute_mode": "local",
  "model": "base",
  "language": "zh"
}
```

### 2. èªéŸ³è½‰æ–‡å­—ï¼ˆä½¿ç”¨é è¨­è¨­å®šï¼‰

```bash
curl -X POST \
  -F "audio_file=@your-audio.mp3" \
  http://localhost:10300/transcribe
```

### 3. èªéŸ³è½‰æ–‡å­—ï¼ˆæŒ‡å®šåƒæ•¸ï¼‰

```bash
curl -X POST \
  -F "audio_file=@your-audio.mp3" \
  -F "language=zh" \
  -F "compute_mode=local" \
  http://localhost:10300/transcribe
```

### 4. ä½¿ç”¨é ç«¯é‹ç®—

```bash
curl -X POST \
  -F "audio_file=@your-audio.mp3" \
  -F "language=zh" \
  -F "compute_mode=remote" \
  -F "remote_host=http://your-gpu-server:10300" \
  http://localhost:10300/transcribe
```

### 5. å‹•æ…‹è¨­å®šé‹ç®—æ¨¡å¼

```bash
# åˆ‡æ›åˆ°æœ¬åœ°é‹ç®—
curl -X POST \
  -F "mode=local" \
  http://localhost:10300/config/compute_mode

# åˆ‡æ›åˆ°é ç«¯é‹ç®—
curl -X POST \
  -F "mode=remote" \
  http://localhost:10300/config/compute_mode

# è¨­å®šé ç«¯ä¼ºæœå™¨
curl -X POST \
  -F "host=http://your-gpu-server:10300" \
  http://localhost:10300/config/remote_host
```

### 6. æª¢æŸ¥ç›®å‰é…ç½®

```bash
curl http://localhost:10300/config
```

## ğŸŒ ç¶²é ç•Œé¢ä½¿ç”¨

ä¿®æ”¹ `web-interface/index.html` ä¸­çš„ä¼ºæœå™¨ç¶²å€ç‚ºï¼š
```
http://your-server:10300
```

ç„¶å¾Œå°±å¯ä»¥é€éç¶²é ç•Œé¢ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆé€²è¡Œè½‰éŒ„ã€‚

## âš™ï¸ é€²éšè¨­å®š

### ç’°å¢ƒè®Šæ•¸å®Œæ•´æ¸…å–®

```bash
# åŸºæœ¬è¨­å®š
WHISPER_MODEL=base              # æ¨¡å‹å¤§å°: tiny, base, small, medium, large
WHISPER_LANG=zh                 # é è¨­èªè¨€: zh, en, ja, ko, auto
WHISPER_THREADS=4               # CPU åŸ·è¡Œç·’æ•¸

# é‹ç®—æ¨¡å¼
COMPUTE_MODE=local              # local, remote, auto
REMOTE_WHISPER_HOST=            # é ç«¯ä¼ºæœå™¨ç¶²å€

# é€²éšè¨­å®š
PYTHONUNBUFFERED=1              # å³æ™‚è¼¸å‡ºæ—¥èªŒ
```

### Docker Compose è¦†è“‹è¨­å®š

å»ºç«‹ `docker-compose.override.yml`ï¼š

```yaml
version: '3.8'
services:
  whisper-flexible:
    environment:
      - COMPUTE_MODE=auto
      - REMOTE_WHISPER_HOST=http://gpu-server:10300
      - WHISPER_MODEL=large
    deploy:
      resources:
        limits:
          memory: 8G
```

## ğŸ” æ•…éšœæ’é™¤

### 1. æœ¬åœ°æ¨¡å‹è¼‰å…¥å¤±æ•—

```bash
# æª¢æŸ¥æ¨¡å‹å¿«å–
ls -la ~/.cache/whisper/

# æ¸…ç†ä¸¦é‡æ–°ä¸‹è¼‰
rm -rf ~/.cache/whisper/
docker-compose restart
```

### 2. é ç«¯é€£æ¥å¤±æ•—

```bash
# æ¸¬è©¦é ç«¯ä¼ºæœå™¨é€£é€šæ€§
curl http://your-gpu-server:10300/health

# æª¢æŸ¥ç¶²è·¯è¨­å®š
docker-compose logs whisper-flexible
```

### 3. è¨˜æ†¶é«”ä¸è¶³

```bash
# ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
export WHISPER_MODEL=tiny

# æˆ–é™åˆ¶ Docker è¨˜æ†¶é«”ä½¿ç”¨
docker-compose down
docker-compose up -d
```

## ğŸš€ æ•ˆèƒ½å»ºè­°

### æœ¬åœ°é‹ç®—
- **CPU**: å»ºè­° 4 æ ¸å¿ƒä»¥ä¸Š
- **è¨˜æ†¶é«”**: æœ€å°‘ 4GBï¼Œæ¨è–¦ 8GB
- **æ¨¡å‹é¸æ“‡**: baseï¼ˆå¹³è¡¡ï¼‰ã€largeï¼ˆé«˜å“è³ªï¼‰

### é ç«¯é‹ç®—
- **ç¶²è·¯**: ç©©å®šçš„å…§ç¶²é€£æ¥
- **å»¶é²**: < 100ms ç‚ºä½³
- **é »å¯¬**: å»ºè­° 100Mbps ä»¥ä¸Š

## ğŸ“Š æ¨¡å‹æ¯”è¼ƒ

| æ¨¡å‹ | å¤§å° | è¨˜æ†¶é«”éœ€æ±‚ | è½‰éŒ„é€Ÿåº¦ | æº–ç¢ºåº¦ |
|------|------|-----------|----------|--------|
| tiny | 39MB | ~1GB | æœ€å¿« | åŸºæœ¬ |
| base | 142MB | ~2GB | å¿« | è‰¯å¥½ |
| small | 244MB | ~3GB | ä¸­ç­‰ | å¾ˆå¥½ |
| medium | 769MB | ~5GB | è¼ƒæ…¢ | å„ªç§€ |
| large | 1550MB | ~10GB | æœ€æ…¢ | æœ€ä½³ |

æ¨è–¦ï¼š**base æ¨¡å‹** åœ¨é€Ÿåº¦å’Œæº–ç¢ºåº¦ä¹‹é–“å–å¾—è‰¯å¥½å¹³è¡¡ã€‚